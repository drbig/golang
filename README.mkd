# Experiments in Golang

Another assorted collection of fun in Golang.
If you have any feedback drop me a line at p.staszewski@gmail.com

Working stuff
-------------

### getlinks.go

Extract links (or actually anything) based on regexps from websites. One major 
feature is support to go through 'all pages' by following a 'Next' or alike 
link (again, regexp matching). You can have more than one extracting regexp per 
URL, and they are processed in parallel. I guess you can do similar stuff with 
httrack or maybe even curl/wget, but I personally prefer to be able to extract 
all links so I can run wget on the right machine in the right time. The code is 
not commented, but then it should be reasonably easy to understand anyway.

### arpapp.go

A 'webapp' that discovers ips via arp cache and then ping-checks them - to 
bring you a succinct report of what is online and what is offline in your 
neighbourhood. It considers itself only with the last state change (keeping 
both the 'since' and 'time elapsed'). It does not clean old entries (i.e. not 
suitable for public routers). Tested on FreeBSD and Linux, works like a charm.

### dhproxy.go

Thanks to [goproxy](https://github.com/elazarl/goproxy) this is basically a 
'one-liner' - it's a simple HTTP proxy that will dump the URI of each request 
that goes through it to stdout.

### wol.go

Simple implementation of 
[Wake-On-Lan](http://en.wikipedia.org/wiki/Wake-on-LAN). This is a part of my 
another 'project' where I implemented this functionality in a number of 
languages (currently C, Go, Ocaml, Ruby and Scheme). Before running you should 
edit the broadcast IP and the static MAC table. Each argument will be first 
looked up in the table, if that fails it will be treated as an MAC address. In 
both cases if the parsing goes ok a magic packet will be sent three times 
(without delay). There is only rudimentary error checking. Tested only on Linux 
(where it works).

### pomf.go

Rather simple uploader for [pomf.se](http://pomf.se). Simple example of using 
`mime/multipart` post a file and `encoding/json` to parse the results. Without 
arguments it will try to upload whatever comes on `stdin`. Otherwise you can 
specify filenames as arguments, and it will try to upload each file. Exits 
successfully only if all uploads were successful and dies very quickly on 
almost any error.

### grabber.go

Purely declarative web scrapper with parallel downloading. Intended to automate 
the common pattern found in websites: archive page pagination - post links - 
resource links. You should open `unixporn.json` example to see the structure of 
a target definition. Non-URL data extraction example is in `golang.json`.

There are two modes: `follow` - use for pagination, and `every` - use for link 
extraction. Then there are three actions that can be taken: `print` - will 
print the link to stdout, `log` - will log the link (either `stdout` or 
`stdin`, depending on the state of the `-log` flag), `download` - will send 
the link to the built-in parallel downloader (which will download only if the 
file doesn't already exist), and finally `raw` - this mode will print to stdout 
whatever was matched, without trying to resolve it into a full URL (this way 
you can use this software to extract pretty much anything).

The `do` actions can be chained in arbitrary manner and form a *command* path 
that will be executed linearly. You can define multiple targets in a single 
file. It will work with SSL connection however it will *not do* any 
verification.

This is by far the most involved piece of software that I have written in 
Golang, and although it's far from beauty, I had a lot of fun writing it.

Depends on [gokogiri](https://github.com/moovweb/gokogiri). Tested under Linux 
and FreeBSD.

### kurier.go

Check the status of your deliveries from the command-line (and *fast*). This 
one uses either XPath or plain old Regexp extractor, so you can deal easily 
with both HTML and JSON. Currently it's setup for the 5 most popular delivery
services in Poland (though UPS link looks like a global one, just change the
language bit). Provide your tracking numbers as arguments. Depends on 
[gokogiri](https://github.com/moovweb/gokogiri) and 
[sanitize](https://github.com/kennygrant/sanitize).

License
-------

Copyright (c) 2012 - 2014 Piotr S. Staszewski

Usual [2-clause BSD license](http://opensource.org/licenses/BSD-2-Clause) for 
everything. See LICENSE.txt for details.
